%!TEX root = ../main-anran-ma.tex 
% so I can build in this tex file too. 
%*****************************************
\chapter{Preliminaries}\label{ch:Preliminaries}
%*****************************************
% \setcounter{theorem}{0}
% \NoCaseChange{Homo Sapiens}
\setcounter{figure}{0}


\section{Notations}\label{sec:notation}
Before proceeding, we clarify the notations used in this thesis, which are not uncommon in materials of computer science and mathematics. 
Readers are encouraged to skip this section and refer back to it if needed. 
The notations and their meaning are listed in \autoref{tab:notation}. 

\begin{table}[ht]\centering
    \begin{tabular}{@{}l;{1pt/1pt}l@{}}
      \hline \hline
      \textbf{Notation}  & \textbf{Meaning} \\\hline
      $\X$     &  set of program variables \\ \hdashline[1pt/1pt]
      $\V$   & set of values\\ \hdashline[1pt/1pt]
      $\sigma:\X\rightarrow\V$   &  program state \\\hdashline[1pt/1pt]
      $\S$  &  set of program states \\\hdashline[1pt/1pt]
      $\C$  &  set of programs \\\hdashline[1pt/1pt]
      $\P$  &  set of predicates \\\hdashline[1pt/1pt]
      $F : \S\rightarrow \{true, false\}$  &  predicate \\
      $F:=\{\sigma\in\S\mid F(\sigma)\}$ \hypertarget{2.*}{(*)} &  the set described by a predicate $F\in\P$ \\ \hdashline[1pt/1pt] 

      \begin{tabular}{@{}l}
        $F(\sigma)$ \hypertarget{2.**}{(**)}\\
        $F(\sigma) = true$ (**)\\ 
        $\sigma\vDash F$   \\
        $\sigma\in F$  
      \end{tabular}        &  
      \begin{tabular}{@{}l}
        state $s$ satisfies predicate $F$; \\
        $F$ is true when system is in state $\sigma$
      \end{tabular}    \\  \hdashline[1pt/1pt]  

      $\sigma\goto{c}\tau$   & 
      \begin{tabular}{@{}l}
        from initial state $\sigma$, an execution of program $c$ \\ 
        terminates at final state $\tau$ 
      \end{tabular}    \\  \hdashline[1pt/1pt] 
      
      \begin{tabular}{@{}l}     
        $\exists x . P : F $\\ 
        $\forall x . P : F $
      \end{tabular} 
      % & syntactic sugar for\ \ 
      %& %if \ \ 
      &\begin{tabular}{@{}c}
        There exists $x$ that satisfies $P$, and also satisfies $F$\\
        % $\exists x. (P\wedge F)$ \\
        All $x$ that satisfy $P$, also satisfy $F$
        % $\forall x. (P\implies F)$
      \end{tabular}
      % $x$ where $P$ is true, then $F$ is true
      \\
      \hline\hline
    \end{tabular}
    \caption{Symbols and Notations}
    \label{tab:notation}
\end{table}

It is worth noting that we regard program states as total functions - we assume that we can assign some default values to variables in case they are undefined. 
We also simplify matters by assuming that there is only one interpretation as a total function from predicates to truth values. 
As a result, we can regard predicates as (total) functions from program states to truth values. 
We also overload the symbols for predicates and use them to identify the sets they describe as shown in \hyperlink{2.*}{Line (*)}. 
% Note that we can have predicates with different symbols that identify the same mapping from program states to truth values: 
% $$P\implies Q  \text{\ \  and\ \  }  \neg P \vee Q$$
% % $P\implies Q$ and $\neg P \vee Q$. 
% But the equivalence of predicates is not the focus of this thesis, and we state that we can use \hyperlink{2.*}{Line (*)} because a predicate uniquely identifies a set of predicates, up to the equivalence relation of predicates. 

By default, we take \mathl{F(\sigma)} to mean the same as \mathl{F(\sigma)= true} for convenience's sake as shown in \hyperlink{2.**}{Lines (**)}. 
We use the equation symbol \mathl{=} to denote equivalences, and the symbols \mathl{:=} for assignments and definitions. 

The operators in descending binding power: $\neg$, $\in$, $\wedge$, $\vee$, ${\implies}$, $Q\_.\_:\_$ where $Q$ is a quantifier: $Q\in\{\exists, \forall\}$. Implication binds to the left: $A{\implies} B{\implies} C$ is equivalent to $(A{\implies} B){\implies} C$.
Now we can proceed to discuss proof rules and systems that are relevant for this thesis. 




\section{Hoare Logic}\label{sec:hoare}
Since the beginning of the 1960s, scholars have been researching the establishment of mathematics in computation~\cite{floyd93, mccarthy93} to have a formal understanding and reasoning of programs. 
One of the most known methods is \define{Hoare logic}. 

In 1969, C.A.R. Hoare wrote \textit{An Axiomatic Basis for Computer Programming}~\cite{hoare69} to explore the logic of computer programs using axioms and inference rules to prove the properties of programs. 
He introduced \imptt{sufficient} preconditions that  guarantee correct results but do not rule out non-termination. 
A selection of the axioms and rules are shown in~\autoref{tab:hoare}.~
\footnote{Non-determinism was not considered in the original paper, so we treat the programs here as deterministic. 
With deterministic programs, one initial state corresponds to one final state.
In case of non-termination, there is simply no final state. }

% \todo{Think about whether to add liberally deterministic (Hesselink 1992, Programs, Recursion and Unbounded Choice). }

\mathl{\{F[x/e]\}} is obtained by substituting occurrences of $x$ by $e$. 

\begin{table}[ht]\centering
    \begin{tabular}{l;{1pt/1pt}l}
      \hline \hline
      \textbf{Axiom of Assignment}     &  \hoare{F[x/e]}{x:=e}{F}   \\ \hdashline[1pt/1pt]
      \textbf{Rules of Consequence}   &  If \hoare{G}{C}{F} and $F\Rightarrow P$ then \hoare{G}{C}{P} \\
                                      &  If \hoare{G}{C}{F} and $P\Rightarrow G$ then \hoare{P}{C}{F} \\ \hdashline[1pt/1pt]
      \textbf{Rule of Composition}   &  If \hoare{G}{C_1}{F_1} and \hoare{F_1}{C_2}{F} then \hoare{G}{C_1;C_2}{F} \\\hdashline[1pt/1pt]
      \textbf{Rule of Iteration}  &  If \hoare{(F\wedge B)}{C}{F} then \hoare{F}{\text{while } B \text{ do } C }{\neg B \wedge F}  \\
      % \textbf{Rule of Condition}   &  $wp.C_1.(wp.C_2.F)$\\
      \hline\hline
    \end{tabular}
    \caption{Inference Rules for Valid Hoare Triple~\protect\footnotemark{}}
    \label{tab:hoare}
\end{table}
\footnotetext{We omit the symbol $\vdash$ in front of a Hoare triple, which denotes ``valid/provable'', for better readability. }

Semantically, a Hoare triple {{\mathl{\hoarenm{G}{C}{F}}}} is said to be valid for (partial) correctness, if the execution of the program $C$ with an initial state satisfying the precondition $G$ leads to a final state that satisfies the postcondition $F$, provided that the program terminates. 
The definitions in \autoref{tab:hoare} indeed correspond to this intended semantics. Formal soundness proofs can be found in Krzysztof R. Apt's survey~\cite{apt81} in 1981.
As an example, consider the rule of composition: if the execution of program $C_1$ changes the state from $G$ to $F_1$, and $C_2$ changes the state from $F_1$ to $F$, then executing them consecutively should bring the program state from $G$ to $F$, with the intermediate state $F_1$.

The missing guarantee of termination can be seen in the rule of iteration: consider the triple {\mathl{\hoarenm{x\leq 2}{\text{while } x\leq 1 \text{ do } x:=x*2}{1<x\leq 2}}}, it is provable in Hoare logic with the following proof tree. 
However, this while-loop will not terminate in case $x\leq 0$ in the initial state.
\begin{center}
\colorbox{ForestGreen!5}{
\begin{prooftree}
  \infer0[]{}
  \infer1[\ \ \textbf{Axiom of Assignment}]{\hoarenm{x\leq 1}{x:=x*2}{x\leq 2}}
  \infer1[\ \ \textbf{Rule of Iteration}]{\hoarenm{x\leq 2}{\text{while } x\leq 1 \text{ do } x:=x*2}{1<x\leq 2}}
\end{prooftree}}
\end{center}

Using style taken from Kaminski's dissertation~\cite{kaminski19}, \autoref{fig:hoare} illustrates a valid Hoare triple: $\S$ represents the set of all states, the section denoted with $G$ includes the states that satisfy the predicate $G$. 
The arrows from left to right denote the executions of program $C$. 
The dashed arrows denote non-terminating executions. 

\begin{figure}[ht]\centering
\includegraphics[width=0.5\textwidth]{image/hoare.eps}
\caption{Valid Hoare Triple (Deterministic)}
\label{fig:hoare}
\end{figure}


A sensible advancement of Hoare logic would be to also prove termination, i.e. to eliminate the arrows from $G$ to the abyss.  
Supplementing Hoare logic with a termination proof is done by Zohar Manna and Amir Pnueli in 1974~\cite{manna74}, where they introduced what is called a \define{loop variant}, a value that decreases with each iteration. The name is in contrast to \define{loop invariant}, concretely the $F$ in \textbf{Rule of Iteration} in \autoref{tab:hoare}, which is constant before and after the loop. 

Another advancement would be to find the \imptt{necessary and sufficient} preconditions that grant us the post-properties, i.e. to eliminate the arrows from $\neg G$ to $F$ in \autoref{fig:hoare}, which  is what Edsger W. Dijkstra accomplished with his \define{weakest precondition} transformer in 1975~\cite{dijkstra75}, among other things. 


\section{Guarded Command Language}\label{sec:gcl}
From now on we use Dijkstra's (non-deterministic) \define{guarded command language (GCL)}~\cite{dijkstra75} to represent programs and to include non-determinism (starting from \autoref{sec:wp-nondet}).
For better readability, we use an equivalent\footnote{Specifically, \mathl{if\ (\varphi)\ \{C_1\}\ else\ \{C_2\}}  is equivalent to
\mathl{if\ \varphi \to C_1\ []\ \neg\varphi \to C_2\ fi} in Dijkstra's original style~\cite{dijkstra75}; \mathl{\{C_1\}\square \{C_2\}} is equivalent to \mathl{if\ true\to C_1\ []\ true\to C_2\ fi}.} 
form of GCL that is similar to modern pseudo-code as shown in \autoref{tab:gcl}. 


\begin{table}[ht!]\centering
    \begin{tabular}{clll}
    $C\ ::=$ 
      & $x:= e$ &  $\mid \ C;C $ & $\mid\  \{C\}\square \{C\} $ \\
      &\footnotesize\define{assignment} &\footnotesize\define{sequential composition} 
      & \footnotesize\define{non-deterministic choice} \\
      &$\mid\  if\ (\varphi)\ \{C\}\ else\ \{C\}$ & $\mid\ while\ (\varphi)\ \{C\}$
      &$\mid\ skip \ \ \ \ \mid\ diverge$ \\ 
      &\footnotesize\define{conditional choice} &\footnotesize\define{while-loop} 
    \end{tabular}
    \caption{Guarded Command Language}
    \label{tab:gcl}
\end{table}

The \define{assignment, sequential composition, conditional choice, while-loop} commands conform to their usual meaning.
The \define{non-deterministic choice} \mathl{\{C_1\}\square \{C_2\}} chooses from two programs non-deterministically. 
It is however not \define{probabilistic}, meaning we do not know the probabilistic distribution of the outcome of the choice. 

When \mathl{skip} is executed, the program state does not change and the consecutive part is executed. 
When \mathl{diverge} is executed, the execution never stops and the program can not reach a final state. 

In our representation of GCL, non-determinism is explicitly constructed via the infix operator \mathl{\square}, whereas in its original definition, non-determinism occurs when the guards within the \mathl{if} and \mathl{while} commands are not mutually exclusive~\cite{dijkstra90}. 
Additionally, the \mathl{if} statement in Dijkstra's GCL is equivalent to divergence in case non of its guards are true, but in our version this can no longer happen because of the Law of Excluded Middle: the predicate $\varphi$ must be either true or false, so either the ``then'' branch or the ``else'' branch is activated.
Consequently, non-termination can only originate from either the \mathl{diverge} or the \mathl{while} command. 


\section{Weakest Preconditions}\label{sec:wp}

\subsection{The Deterministic Case}\label{sec:wp-det}
To better relate Hoare triples and Dijkstra's weakest precondition transformer, we first focus on deterministic programs. 
The goal is to find the \imptt{necessary and sufficient} precondition such that the program is guaranteed to \imptt{terminate} in a state that satisfies the postcondition. 
\autoref{fig:hoare-wp-det} shows it graphically alongside the figure for valid Hoare triples. 
We can see that in \autoref{subfig:wp-det}, the arrows from $G$ to non-termination and from $\neg G$ to $F$ are absent. 

\begin{figure}[ht!]\centering
  \subfloat[Valid Hoare Triple \label{subfig:hoare}]{
    \includegraphics[width=0.45\textwidth]{image/hoare.eps}
  }
  \hfill
  \subfloat[Weakest precondition \label{subfig:wp-det}]{
    \includegraphics[width=0.45\textwidth]{image/wp-det.eps}
  }
\caption{Valid Hoare Triple vs. Weakest Precondition (Deterministic)}
\label{fig:hoare-wp-det}
\end{figure}

The definition of the \define{weakest precondition} transformer is inductively over the program structure in lambda-calculus style\footnote{For example, $wp.C.F$ can be seen as $wp(C,F)$ in ``typical'' style, where wp is treated as a function that has two parameters. The advantage of lambda-calculus style is scalability, we can simply extend the aforementioned function to $wp.C.F.\sigma$ where $\sigma$ means the initial state. Here wp is treated as a function that has three parameters, if we were to write it in the ``typical'' style. It is then questionable whether we changed the type of wp. } as in \autoref{tab:wp-det}: 

\begin{table}[ht!]\centering
    \begin{tabular}{l;{1pt/1pt}l}
    \hline\hline
      \textbf{C}&\textbf{wp.C.F}    \\ \hline
      $skip$&   $F$   \\ \hdashline[1pt/1pt]
      $diverge$&  $false$\\ \hdashline[1pt/1pt]
      $x:= e $&  $F[x/e]$\\ \hdashline[1pt/1pt]
      $C_1;C_2$&  $wp.C_1.(wp.C_2.F)$\\ \hdashline[1pt/1pt]
      $if\ (\varphi)\ \{C_1\}\ else\ \{C_2\} $&  $(\varphi\wedge wp.C_1.F)\vee(\neg\varphi\wedge wp.C_2.F)$\\ \hdashline[1pt/1pt]
      % $\{C_1\}\square \{C_2\}$ & $wp.C_1.F\vee wlp.C_2.F$ \\
      $while\ (\varphi)\ \{C'\}$&  $lfp\ X.(\neg\varphi\wedge F)\vee(\varphi\wedge wp.C'.X)$\\
    \hline\hline
    \end{tabular}
    \caption{The Weakest Precondition Transformer for Deterministic Programs~\cite{kaminski19}}
    \label{tab:wp-det}
\end{table}

A predicate $P$ is \define{weaker} than $Q$, if and only if $Q\implies P$ is valid, and $Q$ is then \define{stronger} than $P$. 
In this case we also say that $P$ is an \define{overapproximation} of $Q$, and $Q$ is an \define{underapproximation} of $P$. 

\mathl{F[x/e]} is $F$ where every occurrence of $x$ is syntactically replaced by $e$. 
\mathl{lfp\ X. f} is the least fixed point of function $f$ with variable $X$. 

Let {$$\Phi(X):=(\neg\varphi\wedge F)\vee(\varphi\wedge wp.C'.X)$$} be the characteristic function, then wp for while-loop can be defined as: 
{$$wp.(while(\varphi)\{C'\}).F = lfp\ X. \Phi(X)$$}

Most of the definitions in \autoref{tab:wp-det} are intuitive and correspond to their counterparts in Hoare logic, while those for \mathl{diverge} and \mathl{while} deserve special attention. 
Since wp aims for total correctness, a program starting in an initial state satisfying the precondition \mathl{wp.diverge.F} should terminate in a final state satisfying the postcondition \mathl{F}. 
Because \mathl{diverge} does not terminate, there is no such precondition and wp for \mathl{diverge} should be \mathl{false}. 

The definition for the while-loop~\cite{kaminski19} is trickier, but we can verify its correctness by recalling Dijkstra's original definition in the following section. 

%\solved{Find out if there's earlier definition that used lfp. -> yes, dijkstra&scholten}

\subsection{Loops and Fixed Points}\label{sec:define loops}
\paragraph{Defining Loops}
In Dijkstra's original paper~\cite{dijkstra75}, he defined wp for while-loops based on its (intended) semantics, i.e. the precondition that guarantees loop termination with the required postcondition within a certain number of iterations. 
Let 
\[
WHILE=while(\varphi)\{C'\}
\\\text{ and } \\ 
IF=  if\ (\varphi)\{C'\}\ else\ \{diverge\}. 
\] 
Note that $IF$ is originally defined as $\underline{if}\ B_1 \to SL_1 \ []\ \dots\ []\ B_n\to SL_n\ \underline{fi}$, where $B_i$ are guards, and $SL_i$ are sub-programs that are executed once their corresponding guards are evaluated to true, thus the name \imptt{guarded} command language.
If multiple guards are true, then any of the corresponding sub-programs can be executed, which is how non-determinism is realized in Dijkstra's GCL. 
If none of the guards is true, then the program does not terminate in a normal state, rather \imptt{diverges}. 

In our flavor of GCL, non-determinism is denoted explicitly with the operator $\square$, and $if\ (\varphi)\ \{C_1\}\ else\ \{C_2\}$ does not lead to divergence in case its guard $\varphi$ evaluates to true, but the $else$-branch if $\varphi$ is not satisfied. 
In essence, the $if$ in our flavor of GCL is equivalent to $\underline{if}\ \varphi \to C_1\ []\ \neg \varphi\to C_2\ \underline{fi}$. 
As a result, to replicate $IF=\underline{if}\ B_1 \to SL_1 \ []\ \dots\ []\ B_n\to SL_n\ \underline{fi}$ where divergence is possible in case none of the guards is true, we need $diverge$ instead of $skip$ in the $else$-branch. 

%\footnote{In our model, the if construct have only one guard $\varphi$, which if written in the original style would be $if \varphi \to C'$ }
Rewriting Dijkstra's definition in a form conforming to our style, he defines 
\[
H_0(F)=( \neg \varphi\wedge F )
\\\text{ and } \\ 
H_k(F)=wp.IF.H_{k-1}(F) \vee H_0(F). 
\]

\mathl{IF} is defined in such way that $wp.IF.X$ is the weakest precondition that makes sure the guard of $C'$ is satisfied once and $C'$ is executed once, leaving the program in a state satisfying $X$.
As a result, $H_k(F)$ corresponds to the weakest precondition such that the program terminates in a final state satisfying $F$ after \imptt{at most} $k$ iterations.


%done{Explain a bit more about how this relate to the above definition. }

Then by definition: 
\begin{equation}
  \hspace{2.5cm}
  wp.WHILE.F=(\exists k\geq 0: H_k(F)) = \underset{k\geq 0}{\bigvee} H_k(F) \label{eq:while}
\end{equation}

\paragraph{Least Fixed Points}
The definition in \autoref{tab:wp-det}, however, uses the least fixed point of the characteristic function $\Phi(X)$. 
We can understand the use of fixed point in two ways. 

Firstly, a precondition $G$ being a fixed point of the characteristic function implies that 
\begin{equation}
  \hspace{2.5cm}
  G= \Phi(G)=(\neg\varphi\wedge F)\vee(\varphi\wedge wp.C'.G) \label{eq:fp}
\end{equation}
This means if $G$ is satisfied before the execution of $WHILE$, then termination is possible (left side of the disjunction) and repeated execution of $C'$ is possible (right side of the disjunction):
For $WHILE$ to enter the loop to execute $C'$, $\phi$ must evaluate to $true$.
Plugging it in \autoref{eq:fp} results in an equation $G=wp.C'.G$, which means that $G$ is invariant before and after the execution of $C'$. 
In other words, after one execution of $C'$, $G$ stays satisfied, which makes a further execution of $C'$ possible.
In short, \textbf{\textit{all fixed points of function $\Phi$ can potentially lead to non-termination}}. 

Secondly, we know that the semantics of $WHILE$ is equivalent to the semantics of $if(\varphi)\{C';WHILE\}\ else\ \{skip\}$~\cite{lukkien1994OperationalSemanticsGeneralized}. 
Note that here the $else$-branch is defined with $skip$ instead of $diverge$ like the previous paragraph, because in case $\neg\varphi$ is true before the execution of $WHILE$, the program simply skips it and executes the next component. 
This corresponds to a \imptt{skip} in the $else$-branch of $IF$. 
We can then derive the need for fixed points: 
\begin{align*} 
  wp.WHILE.F    & \seq wp.(\text{if }(\varphi)\{C';WHILE\}\text{ else }\{skip\}).F \\
                & \seq \varphi\wedge wp.(C';WHILE).F \ \vee \ \neg\varphi\wedge wp.skip.F\\ 
                & \seq \varphi\wedge wp.C'.(wp.WHILE.F)\ \vee\ \neg\varphi\wedge F\\ 
                & \seq \Phi(wp.WHILE.F)\\ 
\end{align*}
The result $wp.WHILE.F = \Phi(wp.WHILE.F)$ means that $wp.WHILE.F$ should be a fixed point of function $\Phi$ by definition.

The question then arises: can we define wp with any fixed point? 
The answer is no. 
In fact, Dijkstra and Scholten~\cite{dijkstra90} later also gave definitions for wp and wlp in an equivalent form of least and greatest fixed points. 
They called it "strongest" and "weakest solution". 
They also proved that it is necessary to use the extreme solutions.
Here, we show the need for \imptt{least} fixed points by verifying that the definition in \autoref{tab:wp-det} coincides with Dijkstra's definition in \autoref{eq:while}.
Thanks to domain theory, we have a heuristic to calculate the least fixed point of $\Phi$. 
%we We borrow a theorem from domain theory that yields a computation for least fixed points, provided they exist: 

\begin{theorem}{lfp}[Kleene's fixed point theorem]~{\normalfont\cite{kaminski19}}
$$lfp\ \Phi = \underset{n\in\N}{sup}\ \Phi^n(false)$$
\end{theorem}

Coincidentally, $H_k(F)$ is the $(k+1)-$th iteration of the characteristic function $\Phi$ from the bottom element, denoted by $\Phi^{k+1}(false)$. 
For all predicates $F$ and all programs $C'$: 
\begin{lemma}{hk-phi}[Correspondance of $H$ and $\Phi$]
$$\forall k\geq 0: H_k(F)=\Phi^{k+1}(false)$$
\end{lemma}

\begin{proof}
Proof by induction. 
\vspace{-0.25cm}\paragraph{Base case: } 
  \begin{align*} 
    \Phi(false)   & = (\neg\varphi\wedge F)\vee(\varphi\wedge wp.C'.false)  & \\ 
                  & = (\neg\varphi\wedge F)\vee(\varphi\wedge false)         && |\ \hypertarget{2.***}{\text{(***)}}\\
                  & = \neg\varphi\wedge F                                    && |\ \text{predicate calculus} \\
                  & = H_0(F)
  \end{align*}
\hyperlink{2.***}{Line (***)} is supported by what Dijkstra called the Law of Excluded Miracle~\cite[p.18]{dijkstra76}: for all programs $C$, $wp.C.false = false$. 
It states that it is impossible for a program to terminate in a state satisfying no postcondition. 

\vspace{-0.25cm}\paragraph{Step case: } 
  \begin{align*} 
    H_{k+1}(F)     & = wp.IF.H_{k}(F) \vee H_0(F) \\
                  & = wp.(if\ (\varphi)\{C'\}\ else\ \{diverge\}).H_{k}(F) \vee H_0(F) \\
                  &\hspace{0.45\textwidth} | \ \text{unfold IF} \\
                  & = (\varphi\wedge wp.C'.H_{k}(F))\vee(\neg\varphi\wedge wp.diverge.H_{k}(F)) \vee H_0(F) \\ 
                  &\hspace{0.45\textwidth} | \ \text{definition of wp} \\
                  & = (\varphi\wedge wp.C'.H_{k}(F))\vee(\neg\varphi\wedge false) \vee H_0(F) \\
                  &\hspace{0.45\textwidth} | \ \text{definition of wp} \\
                  & = (\varphi\wedge wp.C'.\Phi^{k+1}(false)) \vee H_0(F)  \\
                  &\hspace{0.45\textwidth} | \ \text{induction hypothesis} \\
                  & = (\varphi\wedge wp.C'.\Phi^{k+1}(false)) \vee (\neg\varphi\wedge F)  \\
                  & = \Phi^{k+2}(false)  \\
  \end{align*}
\end{proof}
Combining \thm{lfp} and \autoref{eq:while}, as well as the fact that $\Phi^0(false)=false$, we can arrive at the conclusion that 
$$lfp\ \Phi = wp.WHILE.F$$
i.e. the definitions with the least fixed point and Dijkstra's definition are equivalent.
And since least fixed points are unique if they exist, it is necessary to use the \imptt{least} fixed point to define wp in the way intended by Dijkstra. 

Intuitively, all the fixed points of function $\Phi$ that are not the least one can potentially lead to non-termination. 
Only the least fixed point can guarantee termination. 
Remember from \thm{lfp} that $lfp \ \Phi$ is the disjunction of $\Phi^{k}(false)$ for all non-negative $k$, whereas \lem{hk-phi} tells us that $H_k(F)=\Phi^{k+1}(false)$.

Recall from \autoref{eq:while} that $H_k(F)$ is the weakest precondition that the program terminates satisfying $F$ after \imptt{at most} $k$ iterations, so $lfp\ \Phi$ is 
\begin{align*}
  & WHILE \text{ terminates in at most \textbf{0} iterations }\\
  \text{or } & WHILE \text{ terminates in at most \textbf{1} iterations} \\
  \text{or } & WHILE \text{ terminates in at most \textbf{2} iterations} \\
  \dots
\end{align*}
for all $k\in\N$. 
Now assume that some fixed point $p$ of $\Phi$ guarantees termination in $k$ steps, since $lfp\ \Phi$ is the disjunction of all preconditions that guarantee the termination of $WHILE$ in certain steps, we know that $lfp\ \Phi \Leftrightarrow \cdots\vee\ p\ \vee$, hence $p\implies lfp\ \Phi$. 
Since $lfp \ \Phi$ is the \imptt{least} fixed point, there can be no other fixed points that are weaker than the least one. 
In conclusion, $p$ must be the least fixed point of $\Phi$. 

This tells us that all fixed points that are not the least one can potentially lead to non-termination, but only the least fixed point guarantees termination. 
Since wp is concerned with total correctness, the need for least fixed point arises. 

The advantage of using the least fixed point to define wp is that there are heuristics to find it, whereas \autoref{eq:while} excels at giving intuitions for the preconditions that guarantee loop termination. 
% Essentially, they express the same predicate, i.e. the ``weakest'' precondition for while-loops which is unique. 
% Consequently, it means that we can not use other fixed points to define $wp.WHILE$, which are weaker than the least fixed point. 
% For the same reason, we will see that greatest fixed point is necessary to define the weakest liberal precondition. 

\paragraph{Greatest fixed point}
Following from the statement that \textbf{\textit{all fixed points that are not the least one can potentially lead to non-termination}}, it comes naturally that we need the \imptt{greatest} fixed point when defining the weakest \imptt{liberal} precondition, a precondition that includes \imptt{all} initial states that can potentially lead to non-termination (see \autoref{fig:wp-wlp-together}). 
Since all the fixed points can lead to non-termination, we require that $p \implies wlp.WHILE.F$, where $p$ is a fixed point of $\Phi$.
Following the same reasoning as \autoref{eq:fp}, we can conclude that $wlp.C.F$ is a fixed point of $\Phi$. 
Hence, by definition, $wlp.WHILE.F = gfp\ \Phi$. 


\subsection{The Non-Deterministic Case: Angelic vs. Demonic}\label{sec:wp-nondet}
Now we bring the non-deterministic choice back into the picture and add its wp to \autoref{tab:wp-wlp}. 
Here we assume a setting with \define{angelic non-determinism}, where we assume that whenever non-determinism occurs, it will be resolved in our favor.
This means we are optimistic that the non-determinism is likely to resolve to our favor, meaning that we consider an initial state \imptt{can} lead the program execution to terminate in a final state satisfying $F$, we consider it a valid initial state to satisfy the weakest (liberal) precondition. 
Conversely, if we consider the non-deterministic choice to be demonic, then we require that all executions from an initial state \imptt{must} satisfy $F$ for this state to be included in the set of states described by the weakest (liberal) precondition. 

This results in the weakest precondition for our non-deterministic choice being a disjunction of the wp for its subprograms. 
We are hopeful that a precondition satisfying the wp of one of the subprograms can also lead to termination in our desired postcondition. 
This is a design choice that is different from Dijkstra's~\cite{dijkstra75}, where the wp for non-deterministic choice is a conjunction, hinting at a demonic setting. 
Both choices are justifiable, we choose to follow Zhang and Kaminski's work, favoring the resulting Galois connection between the weakest (liberal) precondition transformers and the strongest (liberal) postcondition transformers~\cite{zhang22}. 


\begin{table}[ht!]\centering
    \begin{tabular}{l;{1pt/1pt}l;{1pt/1pt}l}
    \hline\hline
      \textbf{C}&\textbf{wp.C.F} & \textbf{wlp.C.F}   \\ \hline
      $skip$&   $F$ &   $F$   \\ \hdashline[1pt/1pt]
      $diverge$&  $false$&  $true$\\ \hdashline[1pt/1pt]
      $x:= e $&  $F[x/e]$&  $F[x/e]$\\\hdashline[1pt/1pt]
      $C_1;C_2$&  $wp.C_1.(wp.C_2.F)$&  $wlp.C_1.(wlp.C_2.F)$\\\hdashline[1pt/1pt]

      {\color{Maroon}$\{C_1\}\square \{C_2\}$} & {\color{Maroon}$wp.C_1.F\vee wp.C_2.F$} & {\color{Maroon}$wlp.C_1.F\wedge wlp.C_2.F$}\\\hdashline[1pt/1pt]

      $if\ (\varphi)\ \{C_1\} $ &  $(\varphi\wedge wp.C_1.F)$ &  $(\varphi\wedge wlp.C_1.F)$\\
      $\ \ \ \ \ \ \ \  else\ \{C_2\} $&  $\ \ \ \ \ \ \ \ \vee(\neg\varphi\wedge wp.C_2.F)$ &  $\ \ \ \ \ \ \ \ \vee(\neg\varphi\wedge wlp.C_2.F)$\\\hdashline[1pt/1pt]

      {\color{Maroon}$while\ (\varphi)\ \{C'\}$} &  $lfp\ X.\ (\neg\varphi\wedge F)$ & {\color{Maroon} $gfp\ X.\ (\neg\varphi\wedge F)$}\\
       &  $\ \ \ \ \ \ \ \ \vee(\varphi\wedge wp.C'.X)$ & {\color{Maroon} $\ \ \ \ \ \ \ \ \vee(\varphi\wedge wlp.C'.X)$}\\
    \hline\hline
    \end{tabular}
    \caption{The Weakest (Liberal) Precondition Transformer for Non-deterministic Programs~\cite{kaminski19}}
    \label{tab:wp-wlp}
\end{table}

% \begin{table}[ht!]\centering
%     \begin{tabular}{ll}
%     \hline\hline
%       \textbf{C}&\textbf{wp.C.F}    \\ \hline
%       $skip$&   $F$   \\
%       $diverge$&  $false$\\
%       $x:= e $&  $F[x/e]$\\
%       $C_1;C_2$&  $wp.C_1.(wp.C_2.F)$\\
%       $if\ (\varphi)\ \{C_1\}\ else\ \{C_2\} $&  $(\varphi\wedge wp.C_1.F)\vee(\neg\varphi\wedge wp.C_2.F)$\\
%       {\color{Maroon}$\{C_1\}\square \{C_2\}$} & {\color{Maroon}$wp.C_1.F\vee wp.C_2.F$}\\
%       $while\ (\varphi)\ \{C'\}$&  $lfp\ X.(\neg\varphi\wedge F)\vee(\varphi\wedge wp.C'.X)$\\
%     \hline\hline
%     \end{tabular}
%     \caption{The Weakest Precondition Transformer for Non-deterministic Programs~\cite{kaminski19}}
%     \label{tab:wp-nondet}
% \end{table}

\autoref{subfig:wp-angelic} shows wp with non-deterministic programs. 
Each arrow from left to right shows a \imptt{possible} execution of program $C$. 
The effects of demonic and angelic non-determinism is highlighted in green. 
A condition under whose control the required postcondition is \imptt{reachable but not guaranteed} is considered as a valid precondition in an angelic setting (\autoref{subfig:wp-angelic}), but not in a demonic setting (\autoref{subfig:wlp-demonic}). 

% \begin{figure}[ht!]\centering
% \includegraphics[width=0.7\textwidth]{image/wp-nondet.eps}
% \caption{Weakest Precondition (Angelic Non-determinism)}
% \label{fig:wp-nondet}
% \end{figure}

\begin{figure}[ht!]\centering
  \subfloat[wp (angelic non-determinism) \label{subfig:wp-angelic}]{
    \includegraphics[width=0.45\textwidth]{image/wp-angelic.eps}
  }
  \hfill
  \subfloat[wlp (demonic non-determinism) \label{subfig:wlp-demonic}]{
    \includegraphics[width=0.45\textwidth]{image/wlp-demonic.eps}
  }
\caption{Weakest Precondition (Angelic Non-determinism) and Weakest Liberal Precondition (Demonic Non-determinism)}
\label{fig:wp-wlp-together}
\end{figure}

Note that wp with angelic resolution of non-determinism can be satisfied with initial states from which the execution of $C$ may either diverge or terminate satisfying $F$, as shown with the gray arrows in \autoref{subfig:wpa-extended}. 
Similar statements can be said about the negation of wlp with demonic resolution of non-determinism. 
However, to make the graphs clear, we omit drawing the gray arrows unless necessary, because we recon that the essence of the predicate transformers are already captured using graphs similar to \autoref{fig:wp-wlp-together}. 
For completeness' sake, we show all the gray arrows in \autoref{fig:wp-wlp-extended}, but for the remainder of this thesis, we keep the graphs compact. 

\begin{figure}[ht]\centering
  \subfloat[wp (angelic non-determinism) \label{subfig:wpa-extended}]{
    \includesvg[width=0.45\linewidth]{image/wpa-extended.svg}
  }
  \hfill
  \subfloat[wp (demonic non-determinism) \label{subfig:wpd-extended}]{
    \includesvg[width=0.45\linewidth]{image/wpd-extended.svg}
  }
  \hfill\subfloat[wlp (angelic non-determinism) \label{subfig:wlpa-extended}]{
    \includesvg[width=0.45\linewidth]{image/wlpa-extended.svg}
  }
  \hfill\subfloat[wlp (demonic non-determinism) \label{subfig:wlpd-extended}]{
    \includesvg[width=0.45\linewidth]{image/wlpd-extended.svg}
  }
  \caption{Weakest (Liberal) Precondition Transformers with More Detail}
  \label{fig:wp-wlp-extended}
\end{figure}
  

% To justify this definition for the non-deterministic choice, we must first clarify the intended semantics of the wp-transformer. 

% Let \mathl{\exec C} denote the \define{execution} of program $C$ and \mathl{\exec C.\sigma} denote the set of final states that \imptt{can} occur after the execution of $C$. 
% A state is a function that maps a program variable to a value. The set of \define{states} is denoted by \mathl{\Sigma=\{\sigma \mid \sigma: Vars\to Vals\}}. 

% If $C$ is deterministic, then $\exec C.\sigma$ is a set of a single state, either a final state $\sigma'$ or $\bot$, if the execution does not terminate. 
% If $C$ is non-deterministic, $\exec C.\sigma$ can be a set with multiple elements, since multiple final states can be possible. 

% The weakest precondition $wp.C.F$ is then 











\section{Weakest Liberal Preconditions}\label{sec:wlp}
While the wp-transformer excludes non-termination, the wlp-transformer takes a more liberal approach. 
The weakest precondition delivers a precondition so that the program terminates and a state satisfying the postcondition is \imptt{reachable}. 
The weakest liberal precondition, however, delivers a precondition so that the program either terminates satisfying the postcondition, or diverges. 
The postcondition in the wlp setting is \imptt{guaranteed} upon termination, because we regard the non-deterministic choice as demonic, again favoring to establish a Galois connection~\cite{zhang22}. 

The definition of the weakest liberal precondition transformer is in \autoref{tab:wp-wlp}. 
A graphical representation can be found on \autoref{subfig:wlp-demonic}. 

As preluded earlier, greatest fixed points are used to define wlp for while-loops. 
It is an easy choice, since wlp is semantically the \imptt{weakest} liberal precondition, and $wlp.WHILE.F$ should be a fixed point of its characteristic function, similar to \autoref{sec:define loops}. 

\begin{theorem}{gfp}{\normalfont\cite{kaminski19}}[gfp heuristics]
  $gfp\ \Phi = \underset{n\in\N}{sup}\ \Phi^n(true)$
\end{theorem}

%done{Explain the use of gfp. Possibly relate to page 185 of Dijkstra and Scholten 1990 book. }

% \begin{figure}[ht!]\centering
% \includegraphics[width=0.7\textwidth]{image/wlp-det.eps}
% \caption{Weakest Liberal Precondition (Deterministic)}
% \label{fig:wlp-det}
% \end{figure}



\section{Strongest Postconditions}\label{sec:sp}
Following the style to define wp and wlp, Zhang and Kaminski~\cite{zhang22} (re-)defined \define{strongest postconditions} that capture the characteristics of all reachable states after the execution. 
In essence, $sp.C.G$ is a postcondition that is satisfied by \imptt{all} states that are \imptt{reachable} from $G$. 
The definition of the predicate transformer sp is shown in \autoref{tab:sp}. 

\begin{table}[ht!]\centering
    \begin{tabular}{l;{1pt/1pt}l}
    \hline\hline
      \textbf{C}&\textbf{sp.C.G}    \\ \hline
      $skip$&   $G$   \\ \hdashline[1pt/1pt]
      $diverge$&  $false$\\ \hdashline[1pt/1pt]
      $x:= e $&  $\exists a. x=e[x/a] \wedge G[x/a]$\\ \hdashline[1pt/1pt]
      $C_1;C_2$&  $sp.C_2.(sp.C_1.G)$\\ \hdashline[1pt/1pt]
      $\{C_1\}\square \{C_2\}$ & $sp.C_1.G\vee sp.C_2.G$ \\ \hdashline[1pt/1pt]
      $if\ (\varphi)\ \{C_1\}\ else\ \{C_2\} $&  $sp.C_1.(\varphi\wedge G)\vee sp.C_2.(\neg\varphi\wedge G)$\\ \hdashline[1pt/1pt]
      $while\ (\varphi)\ \{C'\}$&  $\neg\varphi \wedge lfp\ X. G\vee sp.C.(\varphi\wedge X)$\\
    \hline\hline
    \end{tabular}
    \caption{The Strongest Postcondition Transformer~\cite{zhang22}}
    \label{tab:sp}
\end{table}

We can also illustrate the behavior of a program controlled by sp in \autoref{fig:sp-angelic}. 
Instead of discussing termination starting from a precondition, sp focuses on reachability of states satisfying postconditions. 
The dotted arrow points to postconditions describing unreachable final states after the execution of $C$. 
For example, no state would satisfy $x=2$ after the execution of $x:=1$. 

\begin{figure}[ht!]\centering
\includegraphics[width=0.45\textwidth]{image/sp-angelic.eps}
\caption{Strongest Postcondition (Angelic Non-determinism)}
\label{fig:sp-angelic}
\end{figure}


\section{Big Step Semantics}\label{sec:big-step}
\define{Big-step semantics} are often seen while reasoning about the semantics of programming languages, it is known to generate simple proofs. 
To express the meaning of GCL programs, we can use big-step semantics to describe executions of a program. 
% This later proved infeasible for our purpose, because of the absence of inference rules for non-termination, which we still show with an example. 
% , so we still show it for GCL programs and hope that it can prove useful for future endeavors.
Taking inspiration from Nipkow and Klein's book~\cite{nipkow2014} we define the big-step semantics in \autoref{tab:big-step}. 

\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\begin{table}[t]
  \normalsize
  \centering
  \framebox{
  $\begin{array}{@{}ccc@{}}
  \displaystyle\frac{}{\sigma\ar{skip}\sigma} skip &
  % \displaystyle\frac{\tau.x=\sigma.e}{\sigma\ar{x:=e}\tau} assign &
  \displaystyle\frac{}{\sigma\ar{x:=e}\sigma(x:=\sigma.e)} assign &
  \\[3ex]
  \displaystyle\frac{\sigma\ar{C_1}\mu,\ \mu\ar{C_2}\tau}{\sigma\ar{C_1;C_2}\tau} seq &
  \displaystyle\frac{\sigma\ar{C_i}\tau,\ i\in\{1,2\}}{\sigma\ar{C_1\square C_2}\tau} choice_i 
  \\[3ex]
  \displaystyle\frac{\sigma\in\varphi,\ \sigma\ar{C_1}\tau}{\sigma\ar{IF}\tau} if_1 &
  \displaystyle\frac{\sigma\notin\varphi,\ \sigma\ar{C_2}\tau}{\sigma\ar{IF}\tau} if_0 
  \\[3ex]
  \displaystyle\frac{\sigma\notin\varphi}{\sigma\ar{WHILE}\sigma} while_0 &
  \displaystyle\frac{\sigma\in\varphi,\ \sigma\goto{C}\mu,\ \mu\goto{WHILE}\tau}{\sigma\ar{WHILE}\tau} while_n
  \\[3ex]
  % \displaystyle\frac{\bot\notin\S}{\sigma\ar{diverge}\bot} diverge &
  % \\[3ex]
  \text{ where } IF{=} if\ (\varphi)\ \{C_1\}\ else\ \{C_2\}\text{, }
  & WHILE{=} while\ (\varphi)\ do\ \{C\}\text{, and } \sigma,\tau,\mu\in\S.
  \end{array}$}
  \caption{Big Step Semantics}
  \label{tab:big-step}
\end{table}

Note that in rule $assign$, we have a formula $\sigma(x:=\sigma.e)$. 
Here we overload the symbol for function application ``.'' so that it applies to \define{expressions} as well, but without specifying the set of expressions which would restrict our programming language. 
An expression $e$ would be evaluated in a usual way, e.g. $x+y$ at state $\sigma$ would evaluate to $\sigma.x + \sigma.y$. 

We also use symbols $\sigma(x:=v)$ to denote a state where the value of variable $x$ is $v$, and all other variables have the same values as in $\sigma$.
In our big-step semantics, divergence is defined to lead to state $\bot$ that is not a part of $\S$. 

Let $\sigma\in\S$ be a non-trivial state, where non-trivial means that $\sigma\vDash true$ is valid. 
To denote non-termination of a program $C$ with initial state $\sigma$, a simple approach is to consider it as equivalent to the non-existence of a state $\tau\in\S$ that $\sigma\ar{C}\tau$. 
This covers the case of divergence, since there is no rule given for $diverge$, there naturally does not exist a final state that program $diverge$ can take a big-step to. 
% since the only inference rule for $diverge$ goes to a state that is not in $\S$. 
Note that divergence is expressed if all executions of a program diverges. 
If only some executions diverge, the terminating executions are captured. 
As an example, consider the program
$$D:=\ (x:=y\ \square\ while\ (true)\ do\ \{x:=z\})$$
First, there is no rule to prove the while-loop on the right hand of the choice. 
Since $\sigma\notin true$ is the same as with our notation, $\sigma\notin \{\sigma\in\S\mid \sigma\vDash true\}$ can not be valid, since we are looking at a non-trivial $\sigma$. 
Consequently, we can not use the $while_0$ rule, hence the last premise of $while_n$ rule will never be fulfilled for this while-loop. 
As a result, we can only capture the left side of the non-deterministic choice: 
\begin{center}
  \begin{prooftree}
    \infer0[$assign$]{\sigma\ar{x:=y}\sigma(x:=\sigma.y)} 
    \infer1[$choice_1$]{\sigma\ar{x:=y\square while\ (true)\ do\ \{x:=z\}}\sigma(x:=\sigma.y)} 
  \end{prooftree}
\end{center}
As a result, we can conclude that $\sigma\ar{D}\tau$. 
This is not problematic for us to reason about wp with angelic non-determinism resolution and wlp with demonic resolution, but some still prefer to be able to explicitly reason about non-terminating runs by extending the big-step semantics~\cite{leroy2009CoinductiveBigstepOperational, nakata2009TraceBasedCoinductiveOperational} or turn to small-step semantics~\cite{nakata2009TraceBasedCoinductiveOperational} and use paths to distinguish between executions. 
For this thesis, we choose another semantics to express soundness properties of predicate transformers, namely the collecting semantics, for their simplicity and elegance.
% ,  another type of semantics that is more suitable, namely the collecting semantics. 
% because we consider wp with angelic resolution of non-determinism, and wlp with demonic, 
% , and we can not express the non-termination of $D$ with the non-existence of $\tau$ such that $\sigma\ar{D}\tau$, as we proposed. 
% In other words, we can not distinguish $D$ from $x:=y$ in this big-stem semantics without reasoning about the structure or length of the proof tree. 
% In fact, there is no rule in \autoref{tab:big-step} with which we can express while-loops where the guard is simply $true$. 

% Since $\neg\exists\tau\in\S:\sigma\ar{C}\tau$ for non-termination is not sufficient, a natural next step is to consider strengthening this requirement, such as modifying the notion of non-termination to: 
% $$\neg\exists\tau\in\S \imptt{\ \wedge\ \tau\neq\sigma\ }: \sigma\ar{C}\tau$$ 

% However, we still can not capture programs with non-terminating executions, such as 
% $x:=x-1\ \square\ diverge$
% $$WHILE := while\ (x>0)\ do\ \{if\ (x>1)\ \{x:=x-1\}\ else\ \{diverge\} \}$$
% Let \imptt{$\sigma.x=2$}, aka $\sigma$ is a state where $x$ evaluates to $2$, and \imptt{$\mu.x=1$}, then we can infer the following result: 
% \begin{center}
%   \colorbox{ForestGreen!5}{
%   \begin{prooftree}
%     \hypo{\sigma\in\{x>1\}} 
%     \infer0[$assign$]{\sigma\ar{x:=x-1}\mu}
%     \hypo{\mu\notin\{x>1\}}
%     \infer1[$while_0$]{\mu\ar{WHILE}\mu}
%     \infer3[$while_n$]{\sigma\ar{WHILE}\mu}
%   \end{prooftree}}
% \end{center}

% In conclusion, this version of big-step semantics proves inadequate to reason with some non-terminating executions. 

% non-termination of $C$ with initial state $\sigma$ is denoted by the non-existence of state $\tau\in\S$ and $\tau\neq\sigma$ such that $\sigma\goto{C}\tau$. 
% Either $diverge$ is executed during the execution of $C$, in which a special state $\bot\notin\S$ is reached, or the execution of $C$ never ends, for example $C=while(true)do skip$.
%TODO: this is not correct, rewrite! 
% With the definition of big-step semantics, we can precisely express the soundness of our predicate transformers in the following section. 

\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\power}[1]{\mathcal{P}(#1)}
\newcommand{\semb}[2]{\llbracket #1 \rrbracket \{#2\}}

\section{Collecting Semantics}\label{sec:collecting}
Zhang and Kaminski assign meaning to GCL programs with a collecting semantics~\cite{zhang22-full}. 
Informally, we ``collect'' reachable states via program execution starting from a set of initial states. 
The definition is shown in \autoref{tab:collect}. 

Let $Conf = \power{\S}$, the set of \define{configurations} in form of the power set of the set of states. 
An element of the $Conf$ set is then a set of program states. 
For a configuration $S$, a \define{filtering} $\sem{\varphi}S:=\{\sigma\mid\sigma\in S \wedge \sigma\vDash\varphi\}$ is the set of program states in $S$ that satisfy the predicate $\varphi$. 
The circle $\circ$ is composition as usual: $(\sem{C_2}\circ\sem{C_1})S = \sem{C_2}(\sem{C_1}S)$. 


\begin{table}[ht!]\centering
  \begin{tabular}{l;{1pt/1pt}l;{1pt/1pt}l}
  \hline\hline
    \textbf{C}&\textbf{$\llbracket$C$\rrbracket$ S}  \\ \hline
    $skip$&   $S$  \\ \hdashline[1pt/1pt]
    $diverge$ & $\emptyset$\\ \hdashline[1pt/1pt]
    $x:= e $& $\{\sigma[x/\sigma(e)]\mid\sigma\in S\}$ \\\hdashline[1pt/1pt]
    $C_1;C_2$&  $(\sem{C_2}\circ\sem{C_1})S$\\\hdashline[1pt/1pt]
    $\{C_1\}\square \{C_2\}$ & $\sem{C_1}S\cup\sem{C_2}S$ \\ \hdashline[1pt/1pt]
    $if\ (\varphi)\ \{C_1\}\ else\ \{C_2\} $ &  $(\sem{C_1}\circ\sem{\varphi})S\cup(\sem{C_2}\circ\sem{\neg\varphi})S$\\ \hdashline[1pt/1pt]
    $while\ (\varphi)\ \{C'\}$&  $\sem{\neg\varphi} (lfp\ X.\ S\cup (\sem{C'}\circ\sem{\varphi})X)$\\
  \hline\hline
  \end{tabular}
  \caption{Collecting Semantics for GCL~\cite{zhang22-full}}
  \label{tab:collect}
\end{table}

Originally, the collecting semantics for $diverge$ and $skip$ was not explicitly given, but since $\sem{\cdot}\cdot$ ``collects'' reachable final states, $\sem{skip}S$ should return $S$, and $\sem{diverge}S$ should be the empty set for any $S$.

We see the difference between this collecting semantics and the big-step semantics for GCL \autoref{sec:big-step} by looking at the same program $D$: 



Remember from \autoref{sec:notation} that a predicate is a function that maps program states to truth values, and it can be written in a set form: $F=\{\sigma\in\S\mid F(\sigma)\}$. 
This gives us two interesting insights: 

First, a configuration corresponds to a class of equivalent predicates. 
Note that we can have predicates in different form that identify the same mapping from program states to truth values, for example 
$$P\implies Q  \text{\ \  and\ \  }  \neg P \vee Q$$
Then the set representation of multiple predicates can be identical to the set of program states described by the configuration. 
Nevertheless, we can see that a configuration is not much different from a predicate. 
Second, a filtering is a set intersection. Rewriting the filtering, we get $\sem{\varphi}S =\{\sigma\mid\sigma\in S \wedge \sigma\in\varphi\} = \varphi\cap S$. 
% \stepcounter{footnote} % for correct footnote numbering
With collecting semantics, we can define the soundness of the predicate transformers in the next section.

% \begin{lemma}{coll-mono} The collecting semantics is monotonic for all programs $C$ and predicates $P$ and $Q$: 
% \[P{\implies} Q \implies \sem{C}P\implies \sem C Q\]  
% \end{lemma}
% \begin{proof}
%   By structural induction on program $C$. 
%   The only not straightforward case is the case with while. 
%   Let $C:=while\ (\varphi)\ \{C'\}$. 
%   Let $L$ denote the weakest fixed point of the function $$f_S(X) =S\cup (\sem{C'}\circ\sem{\varphi})X$$
%   Assume $P\implies Q$, then $\sem{C}P = \sem{\neg \varphi}(P\cup(\sem{C'}\circ\sem{\varphi})L)$. 
%   Remember that a filtering is a set intersection, and we reload the symbols for predicates to also indicate the set of states that satisfy the predicates, then we can we can rewrite $\sem{C}P$ as $\neg \varphi\cap(P\cup(\sem{C'}\circ\sem{\varphi})L)$. 
% \end{proof}

% \begin{theorem}{big-coll} Big-step semantics and collecting semantics are equivalent
% \[\forall C\in\C, \sigma,\tau\in\S : \sigma\ar{C}\tau\ \  \text{ iff } \ \ \tau\in\semb{C}\sigma\]  
% \end{theorem}
% \renewcommand{\iff}{\Leftrightarrow}
% \begin{proof}
%   By structural induction on program $C$. 
%   \paragraph{Cases $skip$, $diverge$, $assign$} Straightforward. 
%   \paragraph{Case $C_1;C_2$} We see from \autoref{tab:big-step} that $\sigma\ar{C_1;C_2}\tau$ must have been proven with the $seq$ rule. 
%   Hence, we have induction hypothesis 
%   \[H_1:=\sigma\ar{C_1}\mu \iff \mu\in\semb{C_1}\sigma\] 
%   \[H_2:=\mu\ar{C_2}\tau \iff \tau\in\semb{C_2}\mu\]
%   Discharging the premises in the $seq$ rule, we conclude that $\mu\in\semb{C_1}\sigma$ and $\tau\in\semb{C_2}\mu$. 
%   As a result, we have that 
%   \begin{align*}
%     (\sem{C_1}\circ\sem{C_2})\{\sigma\} = \sem{C_1}(\sem{C_2}\{\sigma\})
%   \end{align*}
% \end{proof}

\section{Soundness}\label{sec:sound} 
Remember that a predicate is a function from program states to truth values (see \autoref{sec:notation}). 
Then we can apply a predicate to a program state to get its truth value: $wlp.C.F.\sigma$, showing the advantage of using lambda-calculus style notation for function application. 

\begin{theorem}{wp-sound}[Soundness of wp]~{\normalfont\cite{zhang22}} 
\ \vspace{-1.5mm}  
\[
wp.C.F.\sigma = \underset{\tau\in\sem{C}\{\sigma\}}{\bigvee} F.\tau
% wp.C.F = \{\sigma\in\S \mid  \exists \tau\in\S:\ \ \sigma\goto{C}\tau\ \wedge\ \tau\vDash F\}
\]
\end{theorem}

$wp.C.F$ is satisfied exactly by the initial states starting from which the execution of $C$ terminates, and a final state satisfying $F$ is always reachable.
We can rewrite \thm{wp-sound} as\footnote{$\exists\tau\in\S:P$ is short for $\exists\tau.\tau\in\S:P$, and $\forall\tau\in\S:P$ is short for $\forall\tau.\tau\in\S:P$}: 
\[wp.C.F.\sigma = \exists \tau\in\sem{C}\{\sigma\}: F.\tau \]
Recall from \autoref{sec:notation} that predicate $F$ also defines a set $\{\sigma\in\S\mid F.\sigma\}$, then we can rewrite the equation above as: 
\begin{corollary}{wp-sound}[Soundness of wp]
  \[wp.C.F = \{\sigma\in\S\mid\exists\tau\in\sem{C}\{\sigma\}:F.\tau\}\]
\end{corollary}

\begin{theorem}{wlp-sound}[Soundness of wlp]~{\normalfont\cite{zhang22, dijkstra90}}
\ \vspace{-1.5mm} 
\[
wlp.C.F.\sigma = \underset{\tau\in\sem{C}\{\sigma\}}{\bigwedge} F.\tau
% = \{ \sigma\in\S \mid
% \sigma\goto{C}\bot \ \vee\ 
% (\nexists \tau\in\S:\sigma\goto{C}\tau)\ \vee\  this is unnecesssary. 
% \forall \tau\in\S:\ \ \sigma\goto{C}\tau\implies  \tau\vDash F
%  \} %TODO
\]
% \label{thm:wlp}
\end{theorem}
$wlp.C.F$ is satisfied exactly by initial states under whose control the execution of $C$ either never terminates or terminates satisfying $F$. 
Similar to before, we can rewrite \thm{wlp-sound} as: 
\[
  wlp.C.F.\sigma = \forall \tau\in\sem{C}\{\sigma\}: F.\tau
\]
And consequently: 
\begin{corollary}{wlp-sound}[Soundness of wlp]
\[
  wlp.C.F = \{ \sigma\in\S\mid \forall \tau\in\sem{C}\{\sigma\}: F.\tau\}
\]  
\end{corollary}

From \thm{wp-sound} and \thm{wlp-sound}, we see again that the resolving the non-determinism of wp as angelic and that of wlp as demonic is a good choice. 
It yields a simple and elegant way to define the soundness properties of wp and wlp using the collecting semantics. %, which the demonic resolution for wp and angelic resolution for wlp can not achieve. 

To support the reasoning in \autoref{sec:special}, we also need the soundness property of sp: 
\begin{theorem}{sp-sound}[Soundness of sp]~{\normalfont\cite{vries11,zhang22}}
\ \vspace{-1.5mm}
\[
sp.C.G.\tau = \underset{\sigma\ where\ \tau\in\sem{C}\{\sigma\}}{\bigvee} G.\sigma
% sp.C.G = \{ \tau\in\S \mid \exists \sigma\in\S:\ \ \sigma\goto{C}\tau\ \wedge\ \sigma\vDash G\}
\]
% \label{thm:sp}
\end{theorem}

$sp.C.G$ is satisfied exactly by final states that are definitely reachable from some initial state satisfying $G$. 
Similarly, we can rewrite the soundness property of sp as: 
\[sp.C.G.\tau = \exists \sigma.\tau\in\sem{C}\{\sigma\}: G.\sigma\]
And consequently: 
\begin{corollary}{sp-sound}[Soundness of sp]
  \[sp.C.G = \{\tau\in\S\mid \exists\sigma.\tau\in\sem{C}\{\sigma\}: G.\sigma\}\]
\end{corollary}

For completeness' sake, we also state the soundness property of slp: 
\begin{theorem}{slp-sound}[Soundness of slp]~{\normalfont\cite{zhang22}}
  \ \vspace{-1.5mm}
  \[
  slp.C.G.\tau = \underset{\sigma\ where\ \tau\in\sem{C}\{\sigma\}}{\bigwedge} G.\sigma
  \]
\end{theorem}
\begin{corollary}{slp-sound}[Soundness of slp]
  \[slp.C.G = \{\tau\in\S\mid \forall\sigma.\tau\in\sem{C}\{\sigma\}:\ G.\sigma\}\]
\end{corollary}

\section{Properties of wp and wlp}\label{sec:prop}
We also include some properties of predicate transformers in this section that we will need later in \autoref{ch:nlp} for our proofs. 
\begin{theorem}{conjugate}[Conjugates]~{\normalfont\cite{zhang22}}
  wp and wlp are each other's conjugates:
  \[\forall C\in\C:\ \forall F\in\P:\ wp.C.F = \neg wlp.C.\neg F\]
\end{theorem}
This property can be rewritten as $wp.C.F\vee \neg wlp.C.\neg F = true$.
It tells us that wp and wlp complement each other, like in \autoref{fig:wp-wlp-complement}. 

\begin{figure}[ht!]\centering
  \includesvg[width=0.5\textwidth]{image/wp-wlp-complement.svg}
  \caption{wp and wlp Are Conjugates}
  \label{fig:wp-wlp-complement}
\end{figure}


\begin{theorem}{wlp-mono}[Monotonicity]~{\normalfont\cite{dijkstra90}} For any $C\in\C$, $wlp.C$ is monotonic:
  \[\forall X, Y \in\P:\ X{\implies} Y \implies (wlp.C.X\implies Y)\]
\end{theorem}
It states that if we relax the postcondition into a weaker, more general condition, then we should be able to find more initial states that can lead to final states that satisfy this weaker postcondition upon termination. 

\begin{theorem}{wlp-true}~{\normalfont\cite{dijkstra90}}
  $\forall C\in\C:\ wlp.C.true = true$
\end{theorem}
% \[wp.C.false = false\]
% \[wlp.C.true = true\]
% \[wp.C.true = preconditions that lead to termination\]
% \[wlp.C.false = preconditions that lead to non-termination\]
The left side of the equation describes the set of initial states that ``either never terminates, or terminates satisfying $true$'', which describes all initial states, hence it should equal to the set of all states, i.e. a predicate that maps all states to $true$.

\begin{theorem}{wp-false}~{\normalfont\cite{dijkstra90}}[The law of excluded miracle]
  $\forall C\in\C:\ wp.C.false = false$
\end{theorem}
This theorem states that we can not have executions that terminates in a final state satisfying $false$, which would indicate a ``miracle''. 

\medskip
With these theorems, we finish this chapter and the first part of this thesis. 
In the first part, we explain our motivation to study the predicate transformer, then proceed to discuss background information by first list the notations used throughout this thesis. 
Following this, we showcased the relevant formalism for this thesis, namely Hoare triples, the weakest (liberal) precondition transformer, and the strongest postcondition transformer. 

During this process, we give intuition behind the definitions we use, and compare them to their original form. 
We also discuss the different perspectives to resolve non-determinism: angelic versus demonic, and give an excursion about the use of least and greatest fixed points in our definition. 
We also show our attempts to grasp the soundness properties of the predicate transformers using the big-step semantics, and conclude its ineptness for our purpose. 
In conclusion, we choose the collecting semantics to describe the soundness properties of our predicate transformers, and mention some other properties as well. 

Concluding the first part, we proceed in the second part to further study the focus of this thesis. 
We call it the \define{necessary liberal precondition}. 
\imptt{Necessary}, because its violation will lead to violation of the given postcondition, the definition of a necessary condition in logical terms. 
\imptt{Liberal}, because we take a liberal view on non-termination. We accept initial states that can lead to non-termination as satisfying our precondition. 
\imptt{Precondition}, because we are concerned with the conditions before the execution of a program. 


%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
